"""
GPU/CPU çµ±ä¸€è¨ˆç®—å¾Œç«¯å·¥å…·æ¨¡çµ„
æ”¯æŒè‡ªå‹•åˆ‡æ›å’Œå›é€€æ©Ÿåˆ¶
"""
import numpy as np
import warnings
from typing import Union, Optional, Any, Tuple
from functools import wraps
import time
import logging

from config.settings import settings, ComputeBackend

# è¨­ç½®æ—¥èªŒ
logger = logging.getLogger(__name__)

class ComputeManager:
    """è¨ˆç®—å¾Œç«¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self._backend = None
        self._xp = None  # æ•¸çµ„è™•ç†æ¨¡çµ„ (numpy æˆ– cupy)
        self._device = None
        self._gpu_available = False
        self._cupy = None
        self._initialize_backend()
    
    def _initialize_backend(self):
        """åˆå§‹åŒ–è¨ˆç®—å¾Œç«¯"""
        # æª¢æ¸¬GPUå¯ç”¨æ€§
        self._detect_gpu()
        
        # æ ¹æ“šé…ç½®é¸æ“‡å¾Œç«¯
        requested_backend = settings.gpu.backend
        
        if requested_backend == ComputeBackend.AUTO:
            # è‡ªå‹•é¸æ“‡æœ€ä½³å¾Œç«¯
            self._backend = ComputeBackend.GPU if self._gpu_available else ComputeBackend.CPU
        elif requested_backend == ComputeBackend.GPU:
            if not self._gpu_available and settings.gpu.enable_fallback:
                logger.warning("âš ï¸ GPUä¸å¯ç”¨ï¼Œå›é€€åˆ°CPUæ¨¡å¼")
                self._backend = ComputeBackend.CPU
            elif not self._gpu_available:
                raise RuntimeError("âŒ GPUä¸å¯ç”¨ä¸”å·²ç¦ç”¨å›é€€æ¨¡å¼")
            else:
                self._backend = ComputeBackend.GPU
        else:
            self._backend = ComputeBackend.CPU
        
        # è¨­ç½®æ•¸çµ„è™•ç†æ¨¡çµ„
        self._setup_array_module()
        
        # è¨˜éŒ„å¾Œç«¯è³‡è¨Š
        self._log_backend_info()
    
    def _detect_gpu(self):
        """æª¢æ¸¬GPUå¯ç”¨æ€§"""
        try:
            import cupy as cp
            self._cupy = cp
            
            # æ¸¬è©¦GPUåŸºæœ¬åŠŸèƒ½
            test_array = cp.array([1, 2, 3])
            _ = cp.sum(test_array)
            cp.cuda.Device().synchronize()
            
            self._gpu_available = True
            logger.info("âœ… GPU (CUDA) æª¢æ¸¬æˆåŠŸ")
            
        except ImportError:
            logger.info("ğŸ“¦ CuPyæœªå®‰è£ï¼Œä½¿ç”¨CPUæ¨¡å¼")
            self._gpu_available = False
        except Exception as e:
            logger.warning(f"âš ï¸ GPUæª¢æ¸¬å¤±æ•—: {e}")
            self._gpu_available = False
    
    def _setup_array_module(self):
        """è¨­ç½®æ•¸çµ„è™•ç†æ¨¡çµ„"""
        if self._backend == ComputeBackend.GPU and self._gpu_available:
            self._xp = self._cupy
            if settings.gpu.device_id != 0:
                self._cupy.cuda.Device(settings.gpu.device_id).use()
            self._device = self._cupy.cuda.Device()
        else:
            self._xp = np
            self._device = None
    
    def _log_backend_info(self):
        """è¨˜éŒ„å¾Œç«¯è³‡è¨Š"""
        if self._backend == ComputeBackend.GPU:
            gpu_info = self._cupy.cuda.runtime.getDeviceProperties(settings.gpu.device_id)
            memory_info = self._cupy.cuda.MemoryPool().get_limit()
            logger.info(f"ğŸš€ GPUå¾Œç«¯å•Ÿç”¨")
            logger.info(f"ğŸ“± è¨­å‚™: {gpu_info['name'].decode()}")
            logger.info(f"ğŸ’¾ è¨˜æ†¶é«”é™åˆ¶: {memory_info / 1024**3:.1f} GB")
        else:
            logger.info("ğŸ–¥ï¸ CPUå¾Œç«¯å•Ÿç”¨")
    
    @property
    def backend(self) -> ComputeBackend:
        return self._backend
    
    @property
    def xp(self):
        """ç²å–æ•¸çµ„è™•ç†æ¨¡çµ„ (numpy æˆ– cupy)"""
        return self._xp
    
    @property
    def is_gpu_enabled(self) -> bool:
        return self._backend == ComputeBackend.GPU
    
    def asarray(self, array: Union[list, np.ndarray, Any]) -> Any:
        """è½‰æ›ç‚ºé©ç•¶çš„æ•¸çµ„æ ¼å¼"""
        return self._xp.asarray(array)
    
    def to_cpu(self, array: Any) -> np.ndarray:
        """å°‡æ•¸çµ„è½‰æ›å›CPU (numpy)"""
        if self.is_gpu_enabled and hasattr(array, 'get'):
            return array.get()  # cupy array to numpy
        return np.asarray(array)
    
    def to_gpu(self, array: Union[list, np.ndarray]) -> Any:
        """å°‡æ•¸çµ„è½‰æ›åˆ°GPU (å¦‚æœå¯ç”¨)"""
        if self.is_gpu_enabled:
            return self._cupy.asarray(array)
        return np.asarray(array)
    
    def synchronize(self):
        """åŒæ­¥GPUæ“ä½œ (å¦‚æœä½¿ç”¨GPU)"""
        if self.is_gpu_enabled and self._device:
            self._device.synchronize()
    
    def get_memory_info(self) -> dict:
        """ç²å–è¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š"""
        if self.is_gpu_enabled:
            mempool = self._cupy.get_default_memory_pool()
            return {
                'used_bytes': mempool.used_bytes(),
                'total_bytes': mempool.total_bytes(),
                'backend': 'GPU'
            }
        else:
            import psutil
            return {
                'used_bytes': psutil.virtual_memory().used,
                'total_bytes': psutil.virtual_memory().total,
                'backend': 'CPU'
            }

# å…¨åŸŸè¨ˆç®—ç®¡ç†å™¨å¯¦ä¾‹
compute_manager = ComputeManager()

# ä¾¿åˆ©å‡½æ•¸
def get_array_module():
    """ç²å–ç•¶å‰æ•¸çµ„æ¨¡çµ„"""
    return compute_manager.xp

def asarray(array):
    """è½‰æ›ç‚ºç•¶å‰å¾Œç«¯çš„æ•¸çµ„æ ¼å¼"""
    return compute_manager.asarray(array)

def to_cpu(array):
    """è½‰æ›åˆ°CPU"""
    return compute_manager.to_cpu(array)

def to_gpu(array):
    """è½‰æ›åˆ°GPU"""
    return compute_manager.to_gpu(array)

def is_gpu_enabled():
    """æª¢æŸ¥æ˜¯å¦å•Ÿç”¨GPU"""
    return compute_manager.is_gpu_enabled

def synchronize():
    """åŒæ­¥è¨ˆç®—"""
    compute_manager.synchronize()

def gpu_accelerated(fallback_cpu: bool = True):
    """
    è£é£¾å™¨ï¼šç‚ºå‡½æ•¸æä¾›GPUåŠ é€Ÿ
    å¦‚æœGPUä¸å¯ç”¨ä¸”å…è¨±å›é€€ï¼Œè‡ªå‹•ä½¿ç”¨CPUç‰ˆæœ¬
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                result = func(*args, **kwargs)
                if is_gpu_enabled():
                    synchronize()  # ç¢ºä¿GPUæ“ä½œå®Œæˆ
                return result
            except Exception as e:
                if is_gpu_enabled() and fallback_cpu:
                    logger.warning(f"âš ï¸ GPUæ“ä½œå¤±æ•—ï¼Œå›é€€åˆ°CPU: {e}")
                    # é€™è£¡å¯ä»¥å¯¦ç¾CPUç‰ˆæœ¬çš„å›é€€é‚è¼¯
                    raise
                else:
                    raise
        return wrapper
    return decorator

# é«˜æ•ˆèƒ½æ•¸å­¸é‹ç®—å‡½æ•¸
class MathOps:
    """çµ±ä¸€çš„æ•¸å­¸é‹ç®—æ¥å£"""
    
    @staticmethod
    def distance_matrix(points1: Any, points2: Any) -> Any:
        """è¨ˆç®—å…©çµ„é»ä¹‹é–“çš„è·é›¢çŸ©é™£"""
        xp = get_array_module()
        p1 = asarray(points1)
        p2 = asarray(points2)
        
        # å»£æ’­è¨ˆç®—è·é›¢
        diff = p1[:, None, :] - p2[None, :, :]
        distances = xp.sqrt(xp.sum(diff**2, axis=-1))
        return distances
    
    @staticmethod
    def euclidean_distance(p1: Any, p2: Any) -> Any:
        """æ­æ°è·é›¢è¨ˆç®—"""
        xp = get_array_module()
        p1, p2 = asarray(p1), asarray(p2)
        return xp.sqrt(xp.sum((p1 - p2)**2, axis=-1))
    
    @staticmethod
    def interpolate_trajectory(waypoints: Any, num_points: int) -> Any:
        """è»Œè·¡æ’å€¼"""
        xp = get_array_module()
        wp = asarray(waypoints)
        
        # ä½¿ç”¨ç·šæ€§æ’å€¼
        t_old = xp.linspace(0, 1, len(wp))
        t_new = xp.linspace(0, 1, num_points)
        
        interpolated = xp.zeros((num_points, wp.shape[1]))
        for i in range(wp.shape[1]):
            interpolated[:, i] = xp.interp(t_new, t_old, wp[:, i])
        
        return interpolated

# æ•ˆèƒ½ç›£æ§
class PerformanceMonitor:
    """æ•ˆèƒ½ç›£æ§å™¨"""
    
    def __init__(self):
        self.gpu_times = []
        self.cpu_times = []
    
    def time_function(self, func, *args, **kwargs):
        """æ¸¬é‡å‡½æ•¸åŸ·è¡Œæ™‚é–“"""
        start_time = time.perf_counter()
        
        if is_gpu_enabled():
            result = func(*args, **kwargs)
            synchronize()  # ç­‰å¾…GPUæ“ä½œå®Œæˆ
            elapsed = time.perf_counter() - start_time
            self.gpu_times.append(elapsed)
        else:
            result = func(*args, **kwargs)
            elapsed = time.perf_counter() - start_time
            self.cpu_times.append(elapsed)
        
        return result, elapsed
    
    def get_average_times(self) -> dict:
        """ç²å–å¹³å‡åŸ·è¡Œæ™‚é–“"""
        return {
            'gpu_avg': np.mean(self.gpu_times) if self.gpu_times else 0,
            'cpu_avg': np.mean(self.cpu_times) if self.cpu_times else 0,
            'gpu_count': len(self.gpu_times),
            'cpu_count': len(self.cpu_times)
        }

# å…¨åŸŸæ•ˆèƒ½ç›£æ§å™¨
performance_monitor = PerformanceMonitor()

def get_backend_status():
    """ç²å–å¾Œç«¯ç‹€æ…‹è³‡è¨Š"""
    return {
        'backend': compute_manager.backend.value,
        'gpu_available': compute_manager._gpu_available,
        'device_id': settings.gpu.device_id if is_gpu_enabled() else None,
        'memory_info': compute_manager.get_memory_info(),
        'performance': performance_monitor.get_average_times()
    }